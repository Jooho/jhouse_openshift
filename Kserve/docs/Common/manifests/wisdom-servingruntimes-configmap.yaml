kind: ConfigMap
apiVersion: v1
metadata:
  name: servingruntimes-config
data:
  override-config: |
    apiVersion: serving.kserve.io/v1alpha1
    kind: ServingRuntime
    metadata:
      # metadata will be overwritten by the model's metadata
      name: ''
      namespace: ''
      labels:
        name: ''
        opendatahub.io/dashboard: 'true'
      annotations:
        openshift.io/display-name: 'Watson NLP'
    spec:
      supportedModelFormats:
        - autoSelect: true
          name: watson-nlp-custom
      # replicas will be overwritten by the model's replica
      replicas: 1
      protocolVersions:
        - grpc-v1
      multiModel: true
      grpcEndpoint: 'port:8085'
      grpcDataEndpoint: 'port:8001'
      containers:
        - name: watson-nlp-runtime
          image: 'us.icr.io/watson-runtime/fmaas-runtime-ansible-gpu:0.0.4'
          env:
            - name: ACCEPT_LICENSE
              value: 'true'
            - name: LOG_LEVEL
              value: info
            - name: CAPACITY
              value: '28000000000'
            - name: DEFAULT_MODEL_SIZE
              value: '1773741824'
            - name: METRICS_PORT
              value: '2113'
            - name: GATEWAY_PORT
              value: '8060'
            - name: STRICT_RPC_MODE
              value: 'false'
            - name: HF_HOME
              value: /tmp/
          resources:
            limits:
              cpu: 2
              memory: 16Gi
            requests:
              cpu: 1
              memory: 16Gi
      storageHelper:
        disabled: false