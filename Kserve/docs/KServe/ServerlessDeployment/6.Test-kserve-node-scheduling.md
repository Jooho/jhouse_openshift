# Test Kserve Node Scheduling

## Install KServe

Please refer [this doc](./Install-kserve-rhods-on-rosa.md)

## Mandatory Steps
This must be proceeded in the `#Install KServe` but just in case, you should do it again.
~~~
# You should execute this at the jhouse_openshift/Kserve/docs/KServe/ServerlessDeployment
./scripts/setup.sh
source init.sh

cd ${DEMO_HOME}
cp ${KSERVE_MANIFESTS_HOME}/grpc_predict_v2.proto .

oc get ns ${TEST_NS}|| oc new-project ${TEST_NS}
~~~

## Create default ServingRuntimes
~~~
if [[ ! -d ${DEMO_HOME}/kserve ]];then
  cd ${DEMO_HOME}
  git clone https://github.com/kserve/kserve.git 
fi

cd ${DEMO_HOME}/kserve
kustomize build config/runtimes/ |sed "s/ClusterServingRuntime/ServingRuntime/g"|oc create -n kserve-demo -f -
~~~

----

## Pre-requisite

- Enable this feature by KNative
  ~~~
  oc patch configmap config-features -n knative-serving --type json -p '[{"op": "replace", "path": "/data/kubernetes.podspec-affinity", "value": "enabled"}, {"op": "replace", "path": "/data/kubernetes.podspec-nodeselector", "value": "enabled"}, {"op": "replace", "path": "/data/kubernetes.podspec-tolerations", "value": "enabled"}]'

  # data:
  #   kubernetes.podspec-affinity: "enabled"
  #   kubernetes.podspec-nodeselector: "enabled"
  #   kubernetes.podspec-tolerations: "enabled"
  ~~~

## Node Selector
- Add test label to a target node for demo

  ~~~
  TARGET_NODE=$(oc get node --no-headers |head -n1|awk '{print $1}')
  oc label node ${TARGET_NODE} kserve-node-test=cpu
  
  echo "TARGET NODE is ${TARGET_NODE} so the runtime pod must be running on this node if it has the test node selector"

  # (ex)
  # NAME                        STATUS   ROLES    AGE   VERSION
  # ip-10-0-5-92.ec2.internal   Ready    worker   8d    v1.26.7+0ef5eae
  ~~~


- Create a sample model
  ~~~
  oc apply -f ${KSERVE_MANIFESTS_HOME}/tensoflow-flower-sample.yaml

  MODEL_NAME=tensorflow-flower-sample

  wait_for_pods_ready "serving.kserve.io/inferenceservice=${MODEL_NAME}" "${TEST_NS}"
  oc wait --for=condition=ready pod -l serving.kserve.io/inferenceservice=${MODEL_NAME} -n ${TEST_NS} --timeout=300s

  ISVC_URL=$(oc get isvc ${MODEL_NAME} -ojsonpath='{.status.url}')
  INPUT_DATA=${KSERVE_MANIFESTS_HOME}/tensorflow-v1-input-rest-daisy.json

  curl  -k -X POST -H 'accept: application/json'    -H "Content-Type: application/json"   -d @${INPUT_DATA}  ${ISVC_URL}/v1/models/$MODEL_NAME:predict

  oc get pod -o wide -l serving.kserve.io/inferenceservice=${MODEL_NAME}

  #ex) This pod is NOT running on the target node(ip-10-0-5-92.ec2.internal)
  #flowers-sample-predictor-00001-deployment-858d8bc6cf-5xmrg   3/3     Running   0          3m37s   10.129.0.122   ip-10-0-12-56.ec2.internal    #<none>           <none>
  ~~~

- Add test nodeSelector to the sample model isvc
  ~~~
  oc patch isvc ${MODEL_NAME} -p '{"spec":{"predictor":{"nodeSelector": {"kserve-node-test": "cpu"}}}}' --type=merge

  oc get pod -o wide -l serving.kserve.io/inferenceservice=${MODEL_NAME}

  #ex) This pod is running on the target node(ip-10-0-5-92.ec2.internal)
  #flowers-sample-predictor-00001-deployment-858d8bc6cf-5xmrg   1/3     Terminating   0          3m37s   10.129.0.122   ip-10-0-12-56.ec2.internal    #<none>           <none>
  #flowers-sample-predictor-00002-deployment-6d8c7cbc65-bw6rh   3/3     Running       0          71s     10.131.0.104   ip-10-0-5-92.ec2.internal     <none>           <none>
  ~~~

  - ISVC Example
  ~~~
   ...
    predictor:
      model:
        modelFormat:
          name: tensorflow
        name: ""
        resources: {}
        storageUri: gs://kfserving-examples/models/tensorflow/flowers
      nodeSelector:               #<====
        kserve-node-test: cpu     #<====
  ~~~


## Tolerations (TBD)
## NodeSelector + Tolerations (TBD)
## GPU (TBD)


## Cleanup
~~~
oc delete isvc,revision,pod --all -n ${TEST_NS}

# optional
# cd openshift-ai-serving-test
#./commands/kserve-rhods-clean.sh
#./commands/kserve-dependencies-clean.sh
~~~
