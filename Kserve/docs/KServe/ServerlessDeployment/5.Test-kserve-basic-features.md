# Basic features

This document explain with an example not demo. 

## Annotations 
- ServingRuntime
~~~
apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime
metadata:
  name: caikit-runtime
  namespace: kserve-demo
spec:
  annotations:  #<============
    serving.knative.openshift.io/enablePassthrough: "true"
    sidecar.istio.io/inject: "true"
    sidecar.istio.io/rewriteAppHTTPProbers: "true"
  containers:
  - env:
    - name: RUNTIME_LOCAL_MODELS_DIR           
      value: /mnt/models
    image: quay.io/opendatahub/caikit-tgis-serving:stable
    name: kserve-container
    ports:
    - containerPort: 8085
      name: h2c
      protocol: TCP
    resources:
      requests:
        cpu: 4
        memory: 8Gi
  multiModel: false
  supportedModelFormats:
  - autoSelect: true
    name: caikit
~~~

- InferenceService
~~~
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  annotations: #<============
    serving.knative.openshift.io/enablePassthrough: "true"
    sidecar.istio.io/inject: "true"
    sidecar.istio.io/rewriteAppHTTPProbers: "true"
  name: caikit-example-isvc
  namespace: kserve-demo
spec:
  predictor:
    model:
      modelFormat:
        name: caikit
      name: ""
      resources: {}
      runtime: caikit-runtime
      storageUri: s3://modelmesh-example-models/llm/models

~~~

## Environmental variable
- Inferenceservice
~~~
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: caikit-example-isvc
  namespace: kserve-demo
spec:
  predictor:
    model:
      env:      #<==
      - name: test
        value: Jooho
      modelFormat:
        name: caikit
      name: ""
      resources: {}
      runtime: caikit-runtime
      storageUri: s3://modelmesh-example-models/llm/models
~~~


- ServingRuntime
~~~
apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime
metadata:
  name: caikit-runtime
  namespace: kserve-demo
spec:
  containers:
  - env:
    - name: RUNTIME_LOCAL_MODELS_DIR            #<============
      value: /mnt/models
    image: quay.io/opendatahub/caikit-tgis-serving:stable
    name: kserve-container
    ports:
    - containerPort: 8085
      name: h2c
      protocol: TCP
    resources:
      requests:
        cpu: 4
        memory: 8Gi
  multiModel: false
  supportedModelFormats:
  - autoSelect: true
    name: caikit
~~~


## Minimum Pod Count
- ISVC
~~~
apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "flowers-sample"
spec:
  predictor:
    minReplicas: 1 # <==
    model:
      modelFormat:
        name: tensorflow
      storageUri: "gs://kfserving-examples/models/tensorflow/flowers"
~~~

- ServingRuntime
~~~
apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime
metadata:
  name: caikit-runtime
  namespace: kserve-demo
spec:
  replicas: 1 #<=====
  containers:
  - env:
    - name: RUNTIME_LOCAL_MODELS_DIR            
      value: /mnt/models
    image: quay.io/opendatahub/caikit-tgis-serving:stable
    name: kserve-container
    ports:
    - containerPort: 8085
      name: h2c
      protocol: TCP
    resources:
      requests:
        cpu: 4
        memory: 8Gi
  multiModel: false
  supportedModelFormats:
  - autoSelect: true
    name: caikit
~~~    

## Scale To Zero
~~~
apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "flowers-sample"
spec:
  predictor:
    minReplicas: 0 #<===  
    model:
      modelFormat:
        name: tensorflow
      storageUri: "gs://kfserving-examples/models/tensorflow/flowers"
~~~

**Deploy Minio**
~~~
${KSERVE_SCRIPTS_HOME}/deploy-minio.sh
${KSERVE_SCRIPTS_HOME}/create-minio-secret-for-kserve.sh
~~~


*TBD*
Batch

Transformers

Monitoring

Explainability
