apiVersion: inference.networking.x-k8s.io/v1alpha2
kind: InferencePool
metadata:
  labels:
    llm-d.ai/inferenceServing: "true"
    llm-d.ai/model: meta-llama-llama-3-2-3b-instruct
  name: meta-llama-llama-3-2-3b-instruct-inference-pool
  namespace: llmd-test-manual
spec:
  extensionRef:
    failureMode: FailClose
    group: ""
    kind: Service
    name: meta-llama-llama-3-2-3b-instruct-epp-service
  selector:
    llm-d.ai/inferenceServing: "true"
    llm-d.ai/model: meta-llama-llama-3-2-3b-instruct
  targetPortNumber: 8000
